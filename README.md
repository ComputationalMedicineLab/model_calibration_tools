Mode Calibration Visualization Tools
====================================

Installation
------------

```shell
git clone https://github.com/ComputationalMedicineLab/model_calibration_tools.git
cd model_calibration_tools
pip install .  # use -e if you want to develop on the toolkit itself
```


Usage
-----

Suppose we have a binary classifier, some number *N* of instances, and that our
classifier is capable of generating probabilities associated with its
predictions.  Given a chosen class *A*, let `probs` be a 1-dim [array][ndArray] (or
array-like) of length *N* giving the probability per instance that it is a
member of *A* as determined by the classifier. Let `actual` be a 1-dim
array-like of booleans (or 1's and 0's, or other boolean-like data type) that
determines per instance whether or not it was actually a member of the chosen
class.  Our classifier will be considered _well-calibrated_ if, for each
probability *p* in `[0, 1]`, the number of instances predicted to be in *A*
with probability *p* turns out to be close to *p*.  In other words, if our
classifier gives a 70% probability for 100 instances of being in *A*, we want
70 of those instances to _actually_ be in *A* for the classifier to be
well-calibrated.

This module provides a few functions to aid in determining and visualizing how
well calibrated a classifier is.

```python
histograms(probs, actual, bins=100) -> (A, not_A, edges, step)
```
`probs` and `actual` are defined as above, and `bins` specifies the number
of subintervals of `[0, 1]` to calculate.  The instances are grouped by
probability of prediction and then partitioned into two histograms by whether
or not they are actually included in the class.  The first histogram is
therefore all positives by predicted probability, and the second is all
negatives.  This functions also returns an array of the left `edges` of the
histogram and the histogram step-size (`step`), a real.  These values are
useful for plotting the histograms against each other.


```python
kde_calibration_curve(probs, actual, bins=100, kernel='gaussian', bandwidth=0.1) -> (y_true / y_total, y_true, y_total)
```
`probs` and `actual` are defined as above.  We select `bins` points between
0 and 1 on the x axis and generate two curves at those points using [KDE][kde].
For the first curve KDE is trained only on the probabilites of positive
instances; the second is trained on all instance probabilities.  These curves,
`y_true` and `y_total`, are denormalized so that they may be compared directly.
Then the ratio `y_true / y_total` gives us a smoothed calibration curve.  This
functions return the originals two curves as well for plotting purposes


```python
plot_histograms(top, bot, edges, step, *, ax=None) -> Axes
```
`ax` is assumed to be a [matplotlib Axes object][axes], if none is given,
we attempt to find the current one using [`pyplot.gca()`][gca].  We plot the
two histograms given by `histograms` on the given axes as a kind of hybrid
histogram; the positive class is plotted as a positive histogram, the negative
class as negative offsets from the y axis.  For examples please refer to the
ExampleUsage notebook.  The axes object is returned.


```python
plot_kde_calibration_curve(curve, y_true=None, y_total=None, *, label=None, ax=None, bins=100) -> Axes
```
`ax` is as in `plot_histograms`.  Similarly, this function plots the curve
generated by `kde_calibration_curve` on the given axes. If `y_true` and
`y_total` are given, they are projected into the interval `[0, 1]` and plotted
alongside the calibration curve. `bins` must match the value given to
`kde_calibration_curve`.  For examples please refer to the ExampleUsage
notebook.  The axes object is returned.


```python
display_calibration(probs, actual, *, figure=None, bins=100, label=None, kernel='gaussian', bandwidth=0.1, include_source_curves=False) -> Figure
```
This function is a convenience function that runs the whole pipeline and
produces a [matplotlib Figure][figure].  If `figure` is not provided we attempt
to find one using [`pyplot.gcf()`][gcf].  If `include_source_curves` is given,
`y_true` and `y_total` are plotted alongside the calibration curve.  The
histograms are plotted below the calibration curves.  For examples please see
the accompanying ExampleUsage notebook.  The figure is returned.


[ndArray]: https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy-ndarray
[kde]: http://scikit-learn.org/stable/modules/density.html#kernel-density-estimation
[axes]: https://matplotlib.org/api/axes_api.html
[gca]: https://matplotlib.org/api/_as_gen/matplotlib.pyplot.gca.html#matplotlib-pyplot-gca
[figure]: https://matplotlib.org/api/_as_gen/matplotlib.figure.Figure.html#matplotlib-figure-figure
[gcf]: https://matplotlib.org/api/_as_gen/matplotlib.pyplot.gcf.html#matplotlib-pyplot-gcf
